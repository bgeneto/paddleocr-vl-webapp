# =============================================================================
# PaddleOCR-VL Document Parser Configuration
# =============================================================================
# Copy this file to .env and customize as needed
# All values shown are defaults

# =============================================================================
# Streamlit Configuration
# =============================================================================
STREAMLIT_SERVER_HEADLESS=true
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0
STREAMLIT_BROWSER_GATHER_USAGE_STATS=false
STREAMLIT_THEME_BASE=light

# Host port mapping (external port)
STREAMLIT_HOST_PORT=8505

# =============================================================================
# Application Configuration
# =============================================================================
APP_TITLE=PaddleOCR-VL Document Parser
APP_DESCRIPTION=Upload PDF or image files to convert them to Markdown using PaddleOCR-VL with vLLM backend
# Maximum file size in MB
MAX_FILE_SIZE_MB=99
# Maximum number of pages to process for PDFs
MAX_PDF_PAGES=350
# Maximum parallel chunk workers (keep low - API may serialize requests internally)
# Higher values don't help if API processes one request at a time
MAX_PARALLEL_PAGES=2
# Maximum pages to show in preview tab (prevents browser slowdown with large documents)
MAX_PREVIEW_PAGES=10
# Pages per chunk sent to API - THIS IS THE KEY GPU OPTIMIZATION SETTING!
# Higher = better GPU utilization (vLLM batches all pages in chunk together)
# Lower = less VRAM usage but worse GPU utilization
# Recommended: 10-20 for 24GB VRAM, 5-10 for 12GB VRAM, 3-5 for 8GB VRAM
PAGES_PER_CHUNK=16

# =============================================================================
# PaddleOCR-VL API Configuration
# =============================================================================
# API endpoint URL (default uses Docker service name)
PADDLEOCR_VL_API_URL=http://paddleocr-vl-api:8080/layout-parsing
# Request timeout in seconds (increase for large files)
API_TIMEOUT=300

# =============================================================================
# Processing Options (Default values for UI)
# =============================================================================
# Enable document orientation classification
USE_DOC_ORIENTATION_CLASSIFY=false
# Enable document unwarping for curved/distorted images
USE_DOC_UNWARPING=false
# Enable layout detection (recommended for best results)
USE_LAYOUT_DETECTION=true
# Enable chart and diagram recognition
USE_CHART_RECOGNITION=false
# Prettify markdown output
PRETTIFY_MARKDOWN=true
# Return visualization images (slower but useful for debugging)
VISUALIZE_RESULTS=false

# =============================================================================
# Docker/VLM Backend Configuration
# =============================================================================
# VLM inference backend: vllm or fastdeploy
VLM_BACKEND=vllm
# Docker image tag suffix (use 'latest' for online, 'latest-offline' for offline)
API_IMAGE_TAG_SUFFIX=latest-offline
VLM_IMAGE_TAG_SUFFIX=latest-offline
# GPU device ID to use (0, 1, etc.)
GPU_DEVICE_ID=0

# NOTE: vLLM memory settings are configured in vllm_config.yaml (not here)

# =============================================================================
# Logging Configuration
# =============================================================================
LOG_LEVEL=INFO
LOG_FILE=/app/logs/app.log

